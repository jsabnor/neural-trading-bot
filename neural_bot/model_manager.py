"""
Model Manager - GestiÃ³n de modelos neurales con nombres personalizados

Permite guardar, cargar y gestionar mÃºltiples modelos entrenados con nombres
descriptivos en lugar de solo versionado numÃ©rico.
"""

import json
import shutil
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any
import joblib


class ModelManager:
    """Gestor de modelos neurales con sistema de nombrado flexible"""
    
    def __init__(self, models_dir='models'):
        """
        Inicializa el gestor de modelos
        
        Args:
            models_dir: Directorio raÃ­z para almacenar modelos
        """
        self.models_dir = Path(models_dir)
        self.models_dir.mkdir(parents=True, exist_ok=True)
        self.index_file = self.models_dir / 'models_index.json'
        self.index = self._load_index()
    
    def _load_index(self) -> Dict:
        """Carga el Ã­ndice de modelos"""
        if self.index_file.exists():
            try:
                with open(self.index_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ Error cargando Ã­ndice: {e}")
                return {'default_model': None, 'models': {}}
        return {'default_model': None, 'models': {}}
    
    def _save_index(self):
        """Guarda el Ã­ndice de modelos"""
        try:
            with open(self.index_file, 'w', encoding='utf-8') as f:
                json.dump(self.index, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âŒ Error guardando Ã­ndice: {e}")
    
    def save_model(self, model, scaler, name: str, metadata: Optional[Dict] = None) -> bool:
        """
        Guarda un modelo con nombre personalizado
        
        Args:
            model: Modelo de Keras entrenado
            scaler: Scaler de sklearn
            name: Nombre descriptivo del modelo (ej: 'eth_optimized')
            metadata: Metadata adicional (sÃ­mbolos, mÃ©tricas, etc.)
        
        Returns:
            bool: True si se guardÃ³ correctamente
        """
        # Validar nombre
        if not name or not name.replace('_', '').replace('-', '').isalnum():
            print(f"âŒ Nombre invÃ¡lido: {name}")
            return False
        
        # Crear directorio del modelo
        model_path = self.models_dir / name
        model_path.mkdir(parents=True, exist_ok=True)
        
        try:
            # Guardar modelo de Keras
            model_file = model_path / 'model.keras'
            model.save(model_file)
            print(f"ðŸ’¾ Modelo guardado: {model_file}")
            
            # Guardar scaler
            scaler_file = model_path / 'scaler.pkl'
            joblib.dump(scaler, scaler_file)
            print(f"ðŸ’¾ Scaler guardado: {scaler_file}")
            
            # Preparar metadata
            if metadata is None:
                metadata = {}
            
            metadata.update({
                'name': name,
                'saved_at': datetime.now().isoformat(),
                'model_file': str(model_file),
                'scaler_file': str(scaler_file),
            })
            
            # Guardar metadata
            metadata_file = model_path / 'metadata.json'
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            print(f"ðŸ’¾ Metadata guardada: {metadata_file}")
            
            # Actualizar Ã­ndice
            self.index['models'][name] = {
                'path': str(model_path),
                'created_at': metadata['saved_at'],
                'metadata_summary': {
                    'symbols': metadata.get('symbols', []),
                    'accuracy': metadata.get('accuracy', None),
                    'timeframe': metadata.get('timeframe', None),
                }
            }
            
            # Si es el primer modelo, marcarlo como default
            if self.index['default_model'] is None:
                self.index['default_model'] = name
                print(f"âœ… '{name}' marcado como modelo por defecto")
            
            self._save_index()
            print(f"âœ… Modelo '{name}' guardado exitosamente")
            return True
            
        except Exception as e:
            print(f"âŒ Error guardando modelo: {e}")
            # Limpiar en caso de error
            if model_path.exists():
                shutil.rmtree(model_path)
            return False
    
    def load_model(self, name: Optional[str] = None) -> Optional[tuple]:
        """
        Carga un modelo por nombre
        
        Args:
            name: Nombre del modelo. Si es None, carga el default
        
        Returns:
            tuple(model, scaler, metadata) o None si falla
        """
        # Si no se especifica nombre, usar default
        if name is None:
            name = self.index.get('default_model')
            if name is None:
                print("âŒ No hay modelo por defecto configurado")
                return None
            print(f"ðŸ“‚ Cargando modelo por defecto: {name}")
        
        # Verificar que existe en el Ã­ndice
        if name not in self.index['models']:
            # FALLBACK: Verificar si existe el directorio directamente
            # Esto es Ãºtil cuando se suben modelos manualmente (SCP/FTP) sin actualizar el Ã­ndice
            direct_path = self.models_dir / name
            if direct_path.exists() and (direct_path / 'model.keras').exists():
                print(f"âš ï¸ Modelo '{name}' no estÃ¡ en el Ã­ndice, pero existe en disco. Intentando cargar...")
                model_path = direct_path
            else:
                print(f"âŒ Modelo '{name}' no encontrado en Ã­ndice ni en disco")
                return None
        else:
            model_path = Path(self.index['models'][name]['path'])
        
        if not model_path.exists():
            # Intentar ruta relativa si la absoluta falla (por cambio de OS Windows -> Linux)
            relative_path = self.models_dir / model_path.name
            if relative_path.exists():
                model_path = relative_path
            else:
                print(f"âŒ Directorio del modelo no existe: {model_path}")
                return None
        
        try:
            # Cargar modelo
            import tensorflow as tf
            model_file = model_path / 'model.keras'
            # safe_mode=False permite cargar modelos con layers Lambda (ej: attention)
            model = tf.keras.models.load_model(model_file, safe_mode=False)
            print(f"ðŸ“‚ Modelo cargado: {model_file}")
            
            # Cargar scaler
            scaler_file = model_path / 'scaler.pkl'
            scaler = joblib.load(scaler_file)
            print(f"ðŸ“‚ Scaler cargado: {scaler_file}")
            
            # Cargar metadata
            metadata_file = model_path / 'metadata.json'
            with open(metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            print(f"ðŸ“‚ Metadata cargada: {metadata_file}")
            
            return model, scaler, metadata
            
        except Exception as e:
            print(f"âŒ Error cargando modelo '{name}': {e}")
            return None
    
    def list_models(self) -> List[Dict[str, Any]]:
        """
        Lista todos los modelos disponibles con su metadata
        
        Returns:
            List de dicts con informaciÃ³n de cada modelo
        """
        models_list = []
        
        for name, info in self.index['models'].items():
            model_info = {
                'name': name,
                'is_default': (name == self.index['default_model']),
                'created_at': info['created_at'],
                'path': info['path'],
            }
            model_info.update(info.get('metadata_summary', {}))
            models_list.append(model_info)
        
        # Ordenar por fecha de creaciÃ³n (mÃ¡s reciente primero)
        models_list.sort(key=lambda x: x['created_at'], reverse=True)
        
        return models_list
    
    def set_default_model(self, name: str) -> bool:
        """
        Marca un modelo como predeterminado
        
        Args:
            name: Nombre del modelo
        
        Returns:
            bool: True si se estableciÃ³ correctamente
        """
        if name not in self.index['models']:
            print(f"âŒ Modelo '{name}' no encontrado")
            return False
        
        old_default = self.index['default_model']
        self.index['default_model'] = name
        self._save_index()
        
        print(f"âœ… Modelo por defecto cambiado: {old_default} â†’ {name}")
        return True
    
    def delete_model(self, name: str, force: bool = False) -> bool:
        """
        Elimina un modelo
        
        Args:
            name: Nombre del modelo
            force: Si True, permite eliminar el modelo default
        
        Returns:
            bool: True si se eliminÃ³ correctamente
        """
        if name not in self.index['models']:
            print(f"âŒ Modelo '{name}' no encontrado")
            return False
        
        # Proteger modelo default
        if name == self.index['default_model'] and not force:
            print(f"âš ï¸ '{name}' es el modelo por defecto. Usa force=True para eliminarlo")
            return False
        
        try:
            # Eliminar directorio
            model_path = Path(self.index['models'][name]['path'])
            if model_path.exists():
                shutil.rmtree(model_path)
                print(f"ðŸ—‘ï¸ Directorio eliminado: {model_path}")
            
            # Actualizar Ã­ndice
            del self.index['models'][name]
            
            # Si era el default, limpiar
            if name == self.index['default_model']:
                # Intentar asignar otro modelo como default
                if self.index['models']:
                    new_default = list(self.index['models'].keys())[0]
                    self.index['default_model'] = new_default
                    print(f"âœ… Nuevo modelo por defecto: {new_default}")
                else:
                    self.index['default_model'] = None
            
            self._save_index()
            print(f"âœ… Modelo '{name}' eliminado")
            return True
            
        except Exception as e:
            print(f"âŒ Error eliminando modelo: {e}")
            return False
    
    def get_model_metadata(self, name: str) -> Optional[Dict]:
        """
        Obtiene la metadata completa de un modelo
        
        Args:
            name: Nombre del modelo
        
        Returns:
            Dict con metadata o None
        """
        if name not in self.index['models']:
            print(f"âŒ Modelo '{name}' no encontrado")
            return None
        
        model_path = Path(self.index['models'][name]['path'])
        metadata_file = model_path / 'metadata.json'
        
        if not metadata_file.exists():
            print(f"âš ï¸ Archivo de metadata no encontrado para '{name}'")
            return None
        
        try:
            with open(metadata_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ Error leyendo metadata: {e}")
            return None
    
    def get_default_model_name(self) -> Optional[str]:
        """Retorna el nombre del modelo por defecto"""
        return self.index.get('default_model')
